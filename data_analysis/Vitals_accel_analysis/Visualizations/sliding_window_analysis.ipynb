{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a16b1f78",
   "metadata": {},
   "source": [
    "Sliding Window Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8ef97360",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Modules\n",
    "\n",
    "import sys\n",
    "sys.path.append(\"..\")\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import matplotlib.lines as mlines\n",
    "from scipy.io import loadmat\n",
    "import scipy\n",
    "from scipy.stats import ttest_ind, skew, ttest_rel\n",
    "import Actigraph_Metrics\n",
    "from pygt3x.reader import FileReader "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "41e732e2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def MAD_boxplot(sbs, x_mag, window_size=100, show_outlier=True):\n",
    "    # Accelerometry is at 100 Hz, so window_size = 100 means 1 second\n",
    "    \n",
    "    # Output Boxplot for each SBS Score\n",
    "    sbs_mad_dict = {-3: [], -2: [], -1: [], 0: [], 1: [], 2: []}\n",
    "    sbs_skew_dict = {-3: [], -2: [], -1: [], 0: [], 1: [], 2: []}\n",
    "    sbs_stdev_dict = {-3: [], -2: [], -1: [], 0: [], 1: [], 2: []}\n",
    "    sbs_mean_dict = {-3: [], -2: [], -1: [], 0: [], 1: [], 2: []}\n",
    "\n",
    "\n",
    "    # Populate the dictionary with MAD values\n",
    "    for i, sbs_value in enumerate(sbs):    \n",
    "        signal = Actigraph_Metrics.VecMag_MAD(x_mag[i,:], window_size)\n",
    "        sbs_mad_dict[sbs_value].extend(signal)\n",
    "        sbs_skew_dict[sbs_value].append(skew(signal, axis = 0, bias = True))\n",
    "        sbs_stdev_dict[sbs_value].append(np.std(signal))\n",
    "        sbs_mean_dict[sbs_value].append(np.mean(signal))\n",
    "        \n",
    "    fig, ax = plt.subplots(nrows=2, ncols=2, figsize=(10,10))\n",
    "\n",
    "    # Box plot: this version will show the outliers too\n",
    "    ax[0,0].boxplot([sbs_mad_dict[-3], sbs_mad_dict[-2], sbs_mad_dict[-1], sbs_mad_dict[0], sbs_mad_dict[1], sbs_mad_dict[2]], \n",
    "                    labels=['-3','-2', '-1', '0', '1', '2'], showfliers=show_outlier)\n",
    "    ax[0,1].boxplot([sbs_skew_dict[-3], sbs_skew_dict[-2], sbs_skew_dict[-1], sbs_skew_dict[0], sbs_skew_dict[1], sbs_skew_dict[2]], \n",
    "                    labels=['-3','-2', '-1', '0', '1', '2'], showfliers=show_outlier)\n",
    "    ax[1,0].boxplot([sbs_stdev_dict[-3], sbs_stdev_dict[-2], sbs_stdev_dict[-1], sbs_stdev_dict[0], sbs_stdev_dict[1], sbs_stdev_dict[2]], \n",
    "                    labels=['-3','-2', '-1', '0', '1', '2'], showfliers=show_outlier)\n",
    "    ax[1,1].boxplot([sbs_mean_dict[-3], sbs_mean_dict[-2], sbs_mean_dict[-1], sbs_mean_dict[0], sbs_mean_dict[1], sbs_mean_dict[2]], \n",
    "                    labels=['-3','-2', '-1', '0', '1', '2'], showfliers=show_outlier)\n",
    "    #label axes\n",
    "    ax[0,0].set_xlabel('SBS Score', fontsize = 8)\n",
    "    ax[0,0].set_ylabel('MAD', fontsize = 8)\n",
    "    ax[0,1].set_xlabel('SBS Score', fontsize = 8)\n",
    "    ax[0,1].set_ylabel('Skew', fontsize = 8)\n",
    "    ax[1,0].set_xlabel('SBS Score', fontsize = 8)\n",
    "    ax[1,0].set_ylabel('Mean', fontsize = 8)\n",
    "    ax[1,1].set_xlabel('SBS Score', fontsize = 8)\n",
    "    ax[1,1].set_ylabel('Standard Deviation', fontsize = 8)\n",
    "    \n",
    "    # T-test Comparisons\n",
    "    # -2 and 2\n",
    "    # t_stat_mad, p_value_mad = ttest_ind(sbs_mad_dict[2], sbs_mad_dict[-2], equal_var=False)\n",
    "\n",
    "    # print(\"T-test for MAD values:\")\n",
    "    # print(\"T-statistic:\", t_stat_mad)\n",
    "    # print(\"P-value:\", p_value_mad)\n",
    "\n",
    "        # T-test Comparisons\n",
    "    sbs_values = [-2, -1, 0, 1, 2]\n",
    "    for i in range(len(sbs_values)):\n",
    "        for j in range(i + 1, len(sbs_values)):\n",
    "            sbs_i = sbs_values[i]\n",
    "            sbs_j = sbs_values[j]\n",
    "            if sbs_mad_dict[sbs_i] and sbs_mad_dict[sbs_j]:\n",
    "                t_stat_mad, p_value_mad = ttest_ind(sbs_mad_dict[sbs_i], sbs_mad_dict[sbs_j], equal_var=False)\n",
    "                print(f\"T-test for MAD values between SBS Score {sbs_i} and {sbs_j}:\")\n",
    "                print(f\"T-statistic: {t_stat_mad}\")\n",
    "                print(f\"P-value: {p_value_mad}\")\n",
    "                print()\n",
    "\n",
    "    return ax, sbs_mad_dict, sbs_mean_dict, sbs_stdev_dict, sbs_skew_dict\n",
    "\n",
    "def vitals_boxplot(sbs, vitals_signal, window_size=100, show_outlier=True):\n",
    "    # Output Boxplot for each SBS Score\n",
    "    sbs_skew_dict = {-3: [], -2: [], -1: [], 0: [], 1: [], 2: []}\n",
    "    sbs_stdev_dict = {-3: [], -2: [], -1: [], 0: [], 1: [], 2: []}\n",
    "    sbs_mean_dict = {-3: [], -2: [], -1: [], 0: [], 1: [], 2: []}\n",
    "\n",
    "\n",
    "    # Populate the dictionary with MAD values\n",
    "    for i, sbs_value in enumerate(sbs):    \n",
    "        signal = vitals_signal[i]\n",
    "        if np.mean(signal) !=0:\n",
    "            sbs_skew_dict[sbs_value].append(skew(signal))\n",
    "            sbs_stdev_dict[sbs_value].append(np.std(signal))\n",
    "            sbs_mean_dict[sbs_value].append(np.mean(signal))\n",
    "        else:\n",
    "            print(f'not enough data at sbs index {i}, flag_list detected') #flag list was detected here. Note: If you go into matlab to cross-check, be aware matlab indices start at 1\n",
    "    fig, ax = plt.subplots(nrows=1, ncols=3, figsize=(16,6))\n",
    "    \n",
    "    #Drop NaN Values\n",
    "    sbs_skew_dict = {key: [x for x in value if not np.isnan(x)] for key, value in sbs_skew_dict.items()}\n",
    "    sbs_stdev_dict = {key: [x for x in value if not np.isnan(x)] for key, value in sbs_stdev_dict.items()}\n",
    "    sbs_mean_dict = {key: [x for x in value if not np.isnan(x)] for key, value in sbs_mean_dict.items()}\n",
    "    \n",
    "    # Box plot: this version will show the outliers too\n",
    "    ax[1].boxplot([sbs_skew_dict[-3], sbs_skew_dict[-2], sbs_skew_dict[-1], sbs_skew_dict[0], sbs_skew_dict[1], sbs_skew_dict[2]], \n",
    "                    labels=['-3','-2', '-1', '0', '1', '2'], showfliers=show_outlier)\n",
    "    ax[0].boxplot([sbs_stdev_dict[-3], sbs_stdev_dict[-2], sbs_stdev_dict[-1], sbs_stdev_dict[0], sbs_stdev_dict[1], sbs_stdev_dict[2]], \n",
    "                    labels=['-3','-2', '-1', '0', '1', '2'], showfliers=show_outlier)\n",
    "    ax[2].boxplot([sbs_mean_dict[-3], sbs_mean_dict[-2], sbs_mean_dict[-1], sbs_mean_dict[0], sbs_mean_dict[1], sbs_mean_dict[2]], \n",
    "                    labels=['-3','-2', '-1', '0', '1', '2'], showfliers=show_outlier)\n",
    "\n",
    "    #label axes\n",
    "    ax[0].set_xlabel('SBS Score', fontsize = 10)\n",
    "    ax[0].set_ylabel('Stdev', fontsize = 10)\n",
    "    ax[2].set_xlabel('SBS Score', fontsize = 10)\n",
    "    ax[2].set_ylabel('Mean', fontsize = 10)\n",
    "    ax[1].set_xlabel('SBS Score', fontsize = 10)\n",
    "    ax[1].set_ylabel('Skew', fontsize = 10)\n",
    "\n",
    "    # T-test\n",
    "    sbs_values = [-3, -2, -1, 0, 1, 2]\n",
    "    for i in range(len(sbs_values)):\n",
    "        for j in range(i + 1, len(sbs_values)):\n",
    "            sbs_i = sbs_values[i]\n",
    "            sbs_j = sbs_values[j]\n",
    "            if sbs_mean_dict[sbs_i] and sbs_mean_dict[sbs_j]:\n",
    "                t_stat_mean, p_value_mean = ttest_ind(sbs_mean_dict[sbs_i], sbs_mean_dict[sbs_j], equal_var=False)\n",
    "                t_stat_stdev, p_value_stdev = ttest_ind(sbs_stdev_dict[sbs_i], sbs_stdev_dict[sbs_j], equal_var=False)\n",
    "                print(f\"T-test for mean values between SBS Score {sbs_i} and {sbs_j}:\")\n",
    "                print(f\"T-statistic: {t_stat_mean}\")\n",
    "                print(f\"P-value: {p_value_mean}\")\n",
    "                print(f\"T-test for standard deviation values between SBS Score {sbs_i} and {sbs_j}:\")\n",
    "                print(f\"T-statistic: {t_stat_stdev}\")\n",
    "                print(f\"P-value: {p_value_stdev}\")\n",
    "                print()\n",
    "    return ax, sbs_mean_dict, sbs_stdev_dict, sbs_skew_dict\n",
    "\n",
    "def report_quartiles(sbs_mad_dict):\n",
    "    # print quartiles and 90th percentile\n",
    "    quartiles = {}\n",
    "    for sbs_value, mad_list in sbs_mad_dict.items():\n",
    "        quartiles[sbs_value] = {\n",
    "            'Q1': np.percentile(mad_list, 25),\n",
    "            'Q2': np.percentile(mad_list, 50),\n",
    "            'Q3': np.percentile(mad_list, 75),\n",
    "            '90th Percentile': np.percentile(mad_list, 90)\n",
    "        }\n",
    "\n",
    "    # Print quartiles and 90th percentile\n",
    "    for sbs_value, values in quartiles.items():\n",
    "        print(f\"SBS Score: {sbs_value}\")\n",
    "        print(f\"Q1: {values['Q1']}\")\n",
    "        print(f\"Q2 (Median): {values['Q2']}\")\n",
    "        print(f\"Q3: {values['Q3']}\")\n",
    "        print(f\"90th Percentile: {values['90th Percentile']}\")\n",
    "        print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "fef9d822",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data_dir = r'S:\\Sedation_monitoring\\PedAccel_directory\\PedAccel\\data_analysis\\PythonPipeline\\PatientData'\n",
    "# data_dir = r'C:\\Users\\jakes\\Documents\\DT 6 Analysis\\PythonCode\\PedAccel\\data_analysis\\PythonPipeline\\PatientData'\n",
    "data_dir = r'/Users/sidharthraghavan/Library/CloudStorage/OneDrive-Personal/Sid_stuff/PROJECTS/PedAccel/data_analysis/Vitals_accel_analysis/PatientData'\n",
    "window_size = 100 #100 is 1 second worth of time\n",
    "lead_time = 10\n",
    "slice_size_min = 11\n",
    "sr = .5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f0cd87e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_gt3x_data(gt3x_filepath, to_numpy=False, verbose=False):\n",
    "    '''\n",
    "    Load data from GT3X file\n",
    "    Expect data to have 3 columns (X, Y, Z) and a timestamp index\n",
    "    '''\n",
    "    with FileReader(gt3x_filepath) as reader:\n",
    "        df = reader.to_pandas()\n",
    "        df.reset_index(inplace=True)\n",
    "        col_names = df.columns.values.tolist()\n",
    "    if verbose:\n",
    "        print(df.head())\n",
    "        print(col_names)    \n",
    "    if to_numpy:\n",
    "        array = df.to_numpy()\n",
    "        if verbose:\n",
    "            print(array.shape)\n",
    "        return array, col_names\n",
    "\n",
    "    return df, col_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b3bf4b76",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing patient: Patient9\n",
      "Error processing patient Patient9: Expected unicode, got numpy.str_\n",
      "Processing patient: Patient11\n",
      "Error processing patient Patient11: Expected unicode, got numpy.str_\n",
      "Processing patient: Patient14\n",
      "Error processing patient Patient14: Expected unicode, got numpy.str_\n",
      "Processing patient: Patient4\n",
      "Error processing patient Patient4: Expected unicode, got numpy.str_\n"
     ]
    }
   ],
   "source": [
    "def calculate_pre_sbs_stats(patient_dir, patient):\n",
    "    \"\"\"\n",
    "    Calculate statistics from 12-hour window before each SBS score\n",
    "    \"\"\"\n",
    "    # Load raw vitals data\n",
    "    vitals_file = os.path.join(patient_dir, f'{patient}_SickBayData.mat')\n",
    "    vitals_data = loadmat(vitals_file)\n",
    "    \n",
    "    # Extract timestamps and convert to datetime\n",
    "    time_data = vitals_data['time'][0].flatten()\n",
    "    time_strings = [item[0] for item in time_data]\n",
    "    # Convert to datetime with proper format\n",
    "    timestamps = pd.to_datetime(time_strings, format='%m/%d/%Y %I:%M:%S %p')\n",
    "    \n",
    "    # Create DataFrames for each metric with actual timestamps\n",
    "    hr_df = pd.Series(vitals_data['heart_rate'].flatten(), index=timestamps)\n",
    "    spo2_df = pd.Series(vitals_data['SpO2'].flatten(), index=timestamps)\n",
    "    rr_df = pd.Series(vitals_data['respiratory_rate'].flatten(), index=timestamps)\n",
    "    \n",
    "    # Load raw accelerometry data\n",
    "    accel_file = os.path.join(patient_dir, f'{patient}_AccelData.gt3x')\n",
    "    acti_data, acti_names = load_gt3x_data(accel_file)\n",
    "    acti_data['mag'] = np.linalg.norm(acti_data[['X', 'Y', 'Z']].values, axis=1)\n",
    "    acti_data['dts'] = pd.to_datetime(acti_data['Timestamp'], unit='s')\n",
    "    accel_series = acti_data.set_index('dts')['mag']\n",
    "    \n",
    "    # Load SBS data to get timestamps\n",
    "    data_filepath = os.path.join(patient_dir, f'{patient}_SICKBAY_{lead_time}MIN_{slice_size_min - lead_time}MIN_Retro.mat')\n",
    "    sbs_data = loadmat(data_filepath)\n",
    "    # Convert start times to datetime with proper format\n",
    "    sbs_times = pd.to_datetime([str(ts[0]) for ts in sbs_data['start_time'].flatten()], format='%Y-%m-%dT%H:%M:%S')\n",
    "    \n",
    "    # Calculate statistics for 12 hours before each SBS score\n",
    "    window_stats = []\n",
    "    for sbs_time in sbs_times:\n",
    "        # Define 12-hour window before SBS score\n",
    "        window_start = sbs_time - pd.Timedelta(hours=12)\n",
    "        \n",
    "        # Get data in this window\n",
    "        hr_window = hr_df[window_start:sbs_time]\n",
    "        spo2_window = spo2_df[window_start:sbs_time]\n",
    "        rr_window = rr_df[window_start:sbs_time]\n",
    "        accel_window = accel_series[window_start:sbs_time]\n",
    "        \n",
    "        # Calculate statistics\n",
    "        stats = {\n",
    "            'heart_rate': {'mean': hr_window.mean(), 'std': hr_window.std()},\n",
    "            'SpO2': {'mean': spo2_window.mean(), 'std': spo2_window.std()},\n",
    "            'respiratory_rate': {'mean': rr_window.mean(), 'std': rr_window.std()},\n",
    "            'accelerometry': {'mean': accel_window.mean(), 'std': accel_window.std()}\n",
    "        }\n",
    "        window_stats.append(stats)\n",
    "    \n",
    "    return window_stats\n",
    "\n",
    "def normalize_sbs_data(patient_dir, patient, window_stats):\n",
    "    \"\"\"\n",
    "    Normalize the SBS data using the pre-calculated window statistics\n",
    "    \"\"\"\n",
    "    # Load the SBS data\n",
    "    data_filepath = os.path.join(patient_dir, f'{patient}_SICKBAY_{lead_time}MIN_{slice_size_min - lead_time}MIN_Retro.mat')\n",
    "    data = loadmat(data_filepath)\n",
    "    \n",
    "    # Extract data\n",
    "    x_mag = data[\"x_mag\"]\n",
    "    SBS = data[\"sbs\"].flatten()\n",
    "    hr = data['heart_rate']\n",
    "    SpO2 = data['SpO2']\n",
    "    rr = data['respiratory_rate']\n",
    "    \n",
    "    # Normalize each window using its corresponding pre-SBS statistics\n",
    "    normalized_data = {\n",
    "        'heart_rate': [],\n",
    "        'SpO2': [],\n",
    "        'respiratory_rate': [],\n",
    "        'accelerometry': []\n",
    "    }\n",
    "    \n",
    "    for i in range(len(window_stats)):\n",
    "        stats = window_stats[i]\n",
    "        \n",
    "        # Normalize the data\n",
    "        normalized_data['heart_rate'].append((hr[i] - stats['heart_rate']['mean']) / stats['heart_rate']['std'])\n",
    "        normalized_data['SpO2'].append((SpO2[i] - stats['SpO2']['mean']) / stats['SpO2']['std'])\n",
    "        normalized_data['respiratory_rate'].append((rr[i] - stats['respiratory_rate']['mean']) / stats['respiratory_rate']['std'])\n",
    "        normalized_data['accelerometry'].append((x_mag[i] - stats['accelerometry']['mean']) / stats['accelerometry']['std'])\n",
    "    \n",
    "    return normalized_data, SBS\n",
    "\n",
    "# Main processing loop\n",
    "for patient in os.listdir(data_dir):\n",
    "    patient_dir = os.path.join(data_dir, patient)\n",
    "    if os.path.isdir(patient_dir):\n",
    "        print(f\"Processing patient: {patient}\")\n",
    "        \n",
    "        try:\n",
    "            # Calculate statistics from 12 hours before each SBS score\n",
    "            window_stats = calculate_pre_sbs_stats(patient_dir, patient)\n",
    "            \n",
    "            # Normalize the SBS data using these statistics\n",
    "            normalized_data, SBS = normalize_sbs_data(patient_dir, patient, window_stats)\n",
    "            \n",
    "            # Create visualization\n",
    "            plt.figure(figsize=(15, 10))\n",
    "            for metric in ['heart_rate', 'SpO2', 'respiratory_rate', 'accelerometry']:\n",
    "                plt.plot(range(len(normalized_data[metric])), normalized_data[metric], label=metric)\n",
    "            \n",
    "            plt.title(f'Normalized Metrics by SBS Window - {patient}')\n",
    "            plt.xlabel('Window Index')\n",
    "            plt.ylabel('Normalized Value (z-score)')\n",
    "            plt.legend()\n",
    "            plt.grid(True)\n",
    "            plt.show()\n",
    "            \n",
    "            # Optional: Save normalized data\n",
    "            # normalized_data['SBS'] = SBS\n",
    "            # pd.DataFrame(normalized_data).to_csv(f'{patient_dir}/{patient}_normalized_metrics.csv')\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"Error processing patient {patient}: {str(e)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a502f6a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# There is no error handling in place, the .mat file must exist\n",
    "for patient in os.listdir(data_dir):\n",
    "    # filter out non-directories\n",
    "    patient_dir = os.path.join(data_dir, patient)\n",
    "    if os.path.isdir(patient_dir):\n",
    "        # data_filepath_accel = os.path.join(patient_dir, f'{patient}_{lead_time}MIN_{slice_size_min - lead_time}MIN_Validated.mat')           \n",
    "        data_filepath = os.path.join(patient_dir, f'{patient}_SICKBAY_{lead_time}MIN_{slice_size_min - lead_time}MIN_Retro.mat')\n",
    "        \n",
    "        data = loadmat(data_filepath)\n",
    "        x_mag = data[\"x_mag\"]\n",
    "        SBS = data[\"sbs\"].flatten()\n",
    "        \n",
    "        hr = data['heart_rate']\n",
    "        SpO2 = data['SpO2']\n",
    "        rr = data['respiratory_rate']\n",
    "        bps = data['blood_pressure_systolic']\n",
    "        bpm = data['blood_pressure_mean']\n",
    "        bpd = data['blood_pressure_diastolic']\n",
    "        vitals_list = [hr,rr,SpO2,bpm,bps,bpd]\n",
    "        vitals_names = ['hr','rr','spo2','bpm','bps','bpd']\n",
    "        \n",
    "        #Call Functions for Analysis for each patient here!\n",
    "\n",
    "        # ACTIGRAPH BOX PLOTS\n",
    "        ax1, sbs_mad_dict, sbs_mean_dict, sbs_stdev_dict, sbs_skew_dict = MAD_boxplot(SBS, x_mag, window_size, show_outlier=True)\n",
    "        ax1[0,0].set_title(f'MAD distribution by SBS, window=100, {lead_time}min\\n {slice_size_min-lead_time}min ' + patient, fontsize = 8)\n",
    "        ax1[0,1].set_title(f'MAD Skewness distribution by SBS, window=100, {lead_time}min\\n {slice_size_min-lead_time}min ' + patient, fontsize = 8)\n",
    "        ax1[1,0].set_title(f'MAD Mean distribution by SBS, window=100, {lead_time}min\\n {slice_size_min-lead_time}min ' + patient, fontsize = 8)\n",
    "        ax1[1,1].set_title(f'MAD Standard Deviation distribution by SBS, window=100, {lead_time}min\\n {slice_size_min-lead_time}min ' + patient, fontsize = 8)\n",
    "        plt.show()\n",
    "\n",
    "        #VITALS BOX PLOTS\n",
    "        index = 0\n",
    "        for k in  range(len(vitals_list)): \n",
    "            signal = (np.array(vitals_list[k])) \n",
    "            print(f'length of signal window for BoxPlot function: {len(signal[0])}') #should be the number of samples in a window\n",
    "            ax2, sbs_mean_dict, sbs_stdev_dict, sbs_skew_dict = vitals_boxplot(SBS, signal, window_size, show_outlier=True) #boxplot function iterates through 2D array\n",
    "            ax2[0].set_title(f'{vitals_names[index]} Stdev distribution by SBS, {lead_time}min\\n {slice_size_min-lead_time}min ' + patient, fontsize = 8)\n",
    "            ax2[1].set_title(f'{vitals_names[index]} Skewness distribution by SBS, {lead_time}min\\n {slice_size_min-lead_time}min ' + patient, fontsize = 8)\n",
    "            ax2[2].set_title(f'{vitals_names[index]} Mean distribution by SBS, {lead_time}min\\n {slice_size_min-lead_time}min ' + patient, fontsize = 8)\n",
    "            index+=1\n",
    "            plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
