{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "MAD Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "from scipy.io import loadmat\n",
    "import Actigraph_Metrics\n",
    "import numpy as np\n",
    "from scipy import stats\n",
    "import math\n",
    "import itertools \n",
    "import neurokit2 as nk\n",
    "from tsfel import auc, calc_std\n",
    "import pandas as pd\n",
    "\n",
    "#Place MAD data into SBS groups\n",
    "data_dir = r\"C:\\Users\\HP\\Documents\\JHU_Academics\\Research\\DT 6\\NewPedAccel\\VentilatedPatientData\"\n",
    "window_size = 100 # 100 is 1 second worth of time\n",
    "\n",
    "lead_time = 10\n",
    "slice_size_min = 15\n",
    "\n",
    "Tag = \"Nurse\"\n",
    "\n",
    "min = 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "def calc_Exertion(accel_data, hr_data):\n",
    "    auc_accel =  auc(accel_data, sr = 100)\n",
    "    hr_std = calc_std(hr_data)\n",
    "    return auc_accel * hr_std\n",
    "\n",
    "\n",
    "def compute_heart_rate(ecg_signal, sampling_rate):\n",
    "    \"\"\"\n",
    "    Compute heart rate from an ECG signal using the NeuroKit library.\n",
    "\n",
    "    Parameters:\n",
    "        ecg_signal (array-like): The ECG signal.\n",
    "        sampling_rate (int or float): The sampling rate of the ECG signal in Hz.\n",
    "\n",
    "    Returns:\n",
    "        dict: A dictionary containing heart rate (in beats per minute) and processed ECG data.\n",
    "    \"\"\"\n",
    "    try:\n",
    "        # Process the ECG signal\n",
    "        processed_ecg, info = nk.ecg_process(ecg_signal, sampling_rate=sampling_rate)\n",
    "\n",
    "        # Extract the heart rate\n",
    "        heart_rate = processed_ecg[\"ECG_Rate\"].values\n",
    "\n",
    "        return {\n",
    "            \"heart_rate\": heart_rate,\n",
    "            \"processed_ecg\": processed_ecg,\n",
    "            \"info\": info\n",
    "        }\n",
    "    except Exception as e:\n",
    "        print(f\"An error occurred while computing heart rate: {e}\")\n",
    "        return None\n",
    "    \n",
    "    # Replace NaN values with unique timestamps (ensuring no intersection with valid timestamps)\n",
    "def replace_nans_with_unique_timestamps(time_array, replacement_value):\n",
    "    # Convert to pandas datetime if the time_array is not already in pandas datetime format\n",
    "    if not isinstance(time_array, pd.DatetimeIndex):\n",
    "        time_array = pd.to_datetime(time_array)\n",
    "\n",
    "    # Replace NaT (Not a Time) with the replacement value\n",
    "    time_array_with_replacement = time_array.copy()\n",
    "    time_array_with_replacement[time_array.isna()] = pd.to_datetime(replacement_value, errors='coerce')\n",
    "    return time_array_with_replacement\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def plot_signal_with_prn(signal, time, prn, title):\n",
    "    \"\"\"\n",
    "    Plot a signal versus time and draw vertical lines where the prn list contains \"y\".\n",
    "    \n",
    "    Parameters:\n",
    "        signal (list or array-like): The signal data.\n",
    "        time (list or array-like of pandas.Timestamp): The time values corresponding to the signal.\n",
    "        prn (list): A list with \"y\" or other markers. Vertical lines are drawn where \"y\" is present.\n",
    "    \"\"\"\n",
    "    # Plot the signal against time\n",
    "    plt.plot(time, signal, label=\"Signal\", color='b')\n",
    "    \n",
    "    # Draw vertical lines where 'y' is present in prn\n",
    "    for i, value in enumerate(prn):\n",
    "        if value == \"y\":\n",
    "            plt.axvline(x=time[i], color='r', linestyle='--', label=\"PRN Mark\" if i == prn.index(\"y\") else \"\")\n",
    "    \n",
    "    # Label the axes and show the plot\n",
    "    plt.xlabel(\"Time\")\n",
    "    plt.ylabel(\"Signal\")\n",
    "    plt.title(title)\n",
    "    plt.legend()\n",
    "    plt.grid(True)\n",
    "    plt.xticks(rotation=45)  # Rotate x-ticks for better readability\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "<class 'numpy.ndarray'> is not convertible to datetime, at position 0",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[46], line 38\u001b[0m\n\u001b[0;32m     34\u001b[0m ecg_time \u001b[38;5;241m=\u001b[39m ecg_data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mstart_time\u001b[39m\u001b[38;5;124m\"\u001b[39m]\u001b[38;5;241m.\u001b[39mflatten()\n\u001b[0;32m     36\u001b[0m \u001b[38;5;66;03m#Line up the data\u001b[39;00m\n\u001b[1;32m---> 38\u001b[0m accel_time \u001b[38;5;241m=\u001b[39m \u001b[43mreplace_nans_with_unique_timestamps\u001b[49m\u001b[43m(\u001b[49m\u001b[43maccel_time\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m     39\u001b[0m ecg_time \u001b[38;5;241m=\u001b[39m replace_nans_with_unique_timestamps(ecg_time, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m     40\u001b[0m retro_prn_times \u001b[38;5;241m=\u001b[39m replace_nans_with_unique_timestamps(retro_prn_times, \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m3\u001b[39m)\n",
      "Cell \u001b[1;32mIn[44], line 38\u001b[0m, in \u001b[0;36mreplace_nans_with_unique_timestamps\u001b[1;34m(time_array, replacement_value)\u001b[0m\n\u001b[0;32m     35\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreplace_nans_with_unique_timestamps\u001b[39m(time_array, replacement_value):\n\u001b[0;32m     36\u001b[0m     \u001b[38;5;66;03m# Convert to pandas datetime if the time_array is not already in pandas datetime format\u001b[39;00m\n\u001b[0;32m     37\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(time_array, pd\u001b[38;5;241m.\u001b[39mDatetimeIndex):\n\u001b[1;32m---> 38\u001b[0m         time_array \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto_datetime\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtime_array\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     40\u001b[0m     \u001b[38;5;66;03m# Replace NaT (Not a Time) with the replacement value\u001b[39;00m\n\u001b[0;32m     41\u001b[0m     time_array_with_replacement \u001b[38;5;241m=\u001b[39m time_array\u001b[38;5;241m.\u001b[39mcopy()\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\envs\\PHANGS\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:1099\u001b[0m, in \u001b[0;36mto_datetime\u001b[1;34m(arg, errors, dayfirst, yearfirst, utc, format, exact, unit, infer_datetime_format, origin, cache)\u001b[0m\n\u001b[0;32m   1097\u001b[0m         result \u001b[38;5;241m=\u001b[39m _convert_and_box_cache(argc, cache_array)\n\u001b[0;32m   1098\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m-> 1099\u001b[0m         result \u001b[38;5;241m=\u001b[39m \u001b[43mconvert_listlike\u001b[49m\u001b[43m(\u001b[49m\u001b[43margc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mformat\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1100\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m   1101\u001b[0m     result \u001b[38;5;241m=\u001b[39m convert_listlike(np\u001b[38;5;241m.\u001b[39marray([arg]), \u001b[38;5;28mformat\u001b[39m)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\envs\\PHANGS\\Lib\\site-packages\\pandas\\core\\tools\\datetimes.py:435\u001b[0m, in \u001b[0;36m_convert_listlike_datetimes\u001b[1;34m(arg, format, name, utc, unit, errors, dayfirst, yearfirst, exact)\u001b[0m\n\u001b[0;32m    432\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mformat\u001b[39m \u001b[38;5;241m!=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmixed\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[0;32m    433\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m _array_strptime_with_fallback(arg, name, utc, \u001b[38;5;28mformat\u001b[39m, exact, errors)\n\u001b[1;32m--> 435\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m \u001b[43mobjects_to_datetime64\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m    436\u001b[0m \u001b[43m    \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    437\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdayfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    438\u001b[0m \u001b[43m    \u001b[49m\u001b[43myearfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myearfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    439\u001b[0m \u001b[43m    \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    440\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m    441\u001b[0m \u001b[43m    \u001b[49m\u001b[43mallow_object\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[0;32m    442\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    444\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m    445\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m    446\u001b[0m     \u001b[38;5;66;03m# is in UTC\u001b[39;00m\n\u001b[0;32m    447\u001b[0m     out_unit \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39mdatetime_data(result\u001b[38;5;241m.\u001b[39mdtype)[\u001b[38;5;241m0\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\HP\\anaconda3\\envs\\PHANGS\\Lib\\site-packages\\pandas\\core\\arrays\\datetimes.py:2398\u001b[0m, in \u001b[0;36mobjects_to_datetime64\u001b[1;34m(data, dayfirst, yearfirst, utc, errors, allow_object, out_unit)\u001b[0m\n\u001b[0;32m   2395\u001b[0m \u001b[38;5;66;03m# if str-dtype, convert\u001b[39;00m\n\u001b[0;32m   2396\u001b[0m data \u001b[38;5;241m=\u001b[39m np\u001b[38;5;241m.\u001b[39masarray(data, dtype\u001b[38;5;241m=\u001b[39mnp\u001b[38;5;241m.\u001b[39mobject_)\n\u001b[1;32m-> 2398\u001b[0m result, tz_parsed \u001b[38;5;241m=\u001b[39m \u001b[43mtslib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43marray_to_datetime\u001b[49m\u001b[43m(\u001b[49m\n\u001b[0;32m   2399\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2400\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2401\u001b[0m \u001b[43m    \u001b[49m\u001b[43mutc\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mutc\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2402\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdayfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mdayfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2403\u001b[0m \u001b[43m    \u001b[49m\u001b[43myearfirst\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43myearfirst\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2404\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcreso\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mabbrev_to_npy_unit\u001b[49m\u001b[43m(\u001b[49m\u001b[43mout_unit\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[0;32m   2405\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   2407\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m tz_parsed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m   2408\u001b[0m     \u001b[38;5;66;03m# We can take a shortcut since the datetime64 numpy array\u001b[39;00m\n\u001b[0;32m   2409\u001b[0m     \u001b[38;5;66;03m#  is in UTC\u001b[39;00m\n\u001b[0;32m   2410\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m result, tz_parsed\n",
      "File \u001b[1;32mtslib.pyx:414\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mtslib.pyx:596\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "File \u001b[1;32mtslib.pyx:588\u001b[0m, in \u001b[0;36mpandas._libs.tslib.array_to_datetime\u001b[1;34m()\u001b[0m\n",
      "\u001b[1;31mTypeError\u001b[0m: <class 'numpy.ndarray'> is not convertible to datetime, at position 0"
     ]
    }
   ],
   "source": [
    "\n",
    "#There is no error handling in place, the .mat file must exist\n",
    "for patient in os.listdir(data_dir):\n",
    "    # filter out non-directories\n",
    "    patient_dir = os.path.join(data_dir, patient)\n",
    "    if os.path.isdir(patient_dir):\n",
    "\n",
    "\n",
    "        #Retro data for PRN\n",
    "        retro_accel = os.path.join(patient_dir, f'{patient}_{lead_time}MIN_{slice_size_min - lead_time}MIN_Accel_Retro.mat')\n",
    "        if not os.path.isfile(retro_accel):\n",
    "            continue\n",
    "        accel_retro_data = loadmat(retro_accel)\n",
    "        retro_prn_times = accel_retro_data ['start_time'].flatten()\n",
    "        retro_PRN = accel_retro_data['PRN'].flatten()\n",
    "\n",
    "\n",
    "        #Accel data\n",
    "        data_filepath_accel = os.path.join(patient_dir, f'{patient}_{lead_time}MIN_{slice_size_min - lead_time}MIN_Accel_{Tag}.mat')\n",
    "        if not os.path.isfile(data_filepath_accel):\n",
    "            continue\n",
    "\n",
    "        accel_data = loadmat(data_filepath_accel)\n",
    "        x_mag = accel_data[\"x_mag\"]\n",
    "        accel_sbs = accel_data[\"sbs\"].flatten()        \n",
    "        accel_time = accel_data[\"start_time\"].flatten()\n",
    "        \n",
    "        # Load the ECG data\n",
    "        ecg_file_path = os.path.join(patient_dir, f'{patient}_{lead_time}MIN_{slice_size_min - lead_time}MIN_ECG_SBSFinal.mat')\n",
    "        ecg_data = loadmat(ecg_file_path)\n",
    "        ecg1 = ecg_data[\"ecg1\"]\n",
    "        ecg2 = ecg_data[\"ecg2\"]\n",
    "        ecg3 = ecg_data[\"ecg3\"]\n",
    "        ecg_sbs = ecg_data['sbs_score'].flatten()\n",
    "        ecg_time = ecg_data[\"start_time\"].flatten()\n",
    "\n",
    "        #Line up the data\n",
    "\n",
    "        #replace nan values with uniqe time stamps that will later be removed\n",
    "        # accel_time = replace_nans_with_unique_timestamps(accel_time, current_time = pd.Timestamp.now() + pd.Timedelta(minutes=10))\n",
    "        # ecg_time = replace_nans_with_unique_timestamps(ecg_time, pd.Timestamp.now() + pd.Timedelta(minutes=20))\n",
    "        # retro_prn_times = replace_nans_with_unique_timestamps(retro_prn_times, pd.Timestamp.now() + pd.Timedelta(minutes=30))\n",
    "    \n",
    "        # Find the intersection of the start_time values (timestamps)\n",
    "        common_times = np.intersect1d(np.intersect1d(accel_time, ecg_time), retro_prn_times)\n",
    "\n",
    "        # Find the indices for each dataset corresponding to the common times\n",
    "        accel_indices = np.isin(accel_time, common_times)\n",
    "        ecg_indices = np.isin(ecg_time, common_times)\n",
    "        retro_prn_indices = np.isin(retro_prn_times, common_times)\n",
    "\n",
    "        # Filter the accelerometer data by the common start_time values\n",
    "        x_mag = x_mag[accel_indices]\n",
    "        accel_sbs = accel_sbs[accel_indices]\n",
    "        accel_time = accel_time[accel_indices]\n",
    "        \n",
    "        # Filter the ECG data by the common start_time values\n",
    "        ecg1 = ecg1[ecg_indices]\n",
    "        ecg2 = ecg2[ecg_indices]\n",
    "        ecg3 = ecg3[ecg_indices]\n",
    "        ecg_time = ecg_time[ecg_indices]\n",
    "        ecg_sbs = ecg_sbs[ecg_indices]\n",
    "\n",
    "        # Filter the PRN data by the common start_time values\n",
    "        retro_PRN = retro_PRN[retro_prn_indices]\n",
    "        retro_prn_time = retro_prn_times[retro_prn_indices]\n",
    "\n",
    "\n",
    "        exertion1 = []\n",
    "        exertion2 = []\n",
    "        exertion3 = []\n",
    "        times = []\n",
    "        PRNs = [] #Need retrospective ecg data to use PRN info\n",
    "\n",
    "        for i in range(len(accel_sbs) - 1):\n",
    "            if(retro_prn_times[i] == accel_time[i] and accel_time[i] == ecg_time[i]): #check there is a time when all ecg nurse and retro accel line up\n",
    "                print(\"Calculating metric\")\n",
    "                PRNs.append(retro_PRN)\n",
    "\n",
    "                accel_signal = x_mag[i]\n",
    "                MAD_accel = Actigraph_Metrics.VecMag_MAD(accel_signal, window=100)\n",
    "\n",
    "                ecg1_signal = ecg1[i]\n",
    "                ecg2_signal = ecg2[\"ecg2\"][i]\n",
    "                ecg3_signal = ecg3[\"ecg3\"][i]\n",
    "\n",
    "                HR_dict1 = compute_heart_rate(ecg1_signal, 250)\n",
    "                HR1 = HR_dict1[\"heart_rate\"]\n",
    "\n",
    "                HR_dict2 = compute_heart_rate(ecg2_signal, 250)\n",
    "                HR2 = HR_dict2[\"heart_rate\"]            \n",
    "                \n",
    "                HR_dict3 = compute_heart_rate(ecg3_signal, 250)\n",
    "                HR3 = HR_dict3[\"heart_rate\"]\n",
    "\n",
    "                exertion_score_1 = calc_Exertion(MAD_accel, HR1)\n",
    "                exertion1.append(exertion_score_1)\n",
    "\n",
    "                exertion_score_2 = calc_Exertion(MAD_accel, HR2)\n",
    "                exertion2.append(exertion_score_2)\n",
    "\n",
    "                exertion_score_3 = calc_Exertion(MAD_accel, HR3)\n",
    "                exertion3.append(exertion_score_3)\n",
    "\n",
    "                times.append(accel_time[i])\n",
    "\n",
    "    plot_signal_with_prn(exertion1, times, PRNs, title = \"ecg1 exertion metric with prn markers\")\n",
    "    plot_signal_with_prn(exertion2, times, PRNs, title = \"ecg2 exertion metric with prn markers\")\n",
    "    plot_signal_with_prn(exertion3, times, PRNs, title = \"ecg3 exertion metric with prn markers\")\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PHANGS",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
